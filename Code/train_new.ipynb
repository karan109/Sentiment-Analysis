{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_new.ipynb","provenance":[],"mount_file_id":"1XvyClzl4nSk5jFTN7YSJDb7LHHfNzEdH","authorship_tag":"ABX9TyM35H+8HJkKhMUrdeKJb2zo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"T30JdHljrqyp","colab_type":"code","colab":{}},"source":["import numpy as np\n","import codecs\n","from keras.layers.embeddings import Embedding\n","from keras.layers import Dense, Input\n","from keras.layers import Flatten\n","from keras.layers import LSTM\n","from keras.layers import Bidirectional\n","from keras.preprocessing import sequence\n","from keras.layers import Dropout\n","from keras.models import Model\n","from keras.models import load_model\n","from keras.callbacks import ModelCheckpoint"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ACDAqgEKsCDJ","colab_type":"code","colab":{}},"source":["path = '/content/drive/My Drive/Sentiment Analysis/'\n","def load_embeddings(embedding_path, glove_len):\n","  weight_vectors = [np.zeros((glove_len, ))]\n","  word_idx = {}\n","  with codecs.open(embedding_path, encoding='utf-8') as f:\n","    for line in f:\n","      word, vec = line.split(u' ', 1)\n","      word_idx[word.lower()] = len(weight_vectors)\n","      weight_vectors.append(np.array(vec.split(), dtype=np.float32))\n","  word_idx[u'-LRB-'] = word_idx.pop(u'(')\n","  word_idx[u'-RRB-'] = word_idx.pop(u')')\n","  weight_vectors.append(np.random.uniform(\n","      -0.05, 0.05, weight_vectors[0].shape).astype(np.float32))\n","  return np.asarray(np.stack(weight_vectors)), word_idx\n","\n","emb_matrix, word_idx = load_embeddings(path+'Data/glove_6B_100d.txt', 100)\n","max_len = 56"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f9hSCWGVuVNU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596094781434,"user_tz":-330,"elapsed":36704,"user":{"displayName":"Karan Aggarwal","photoUrl":"","userId":"14241836093579771442"}},"outputId":"8d446cd5-df00-4f5a-e7bf-6077e1946194"},"source":["X_train = np.load(path+'Data/X_train.npy')\n","X_test = np.load(path+'Data/X_test.npy')\n","X_dev = np.load(path+'Data/X_dev.npy')\n","Y_train = np.load(path+'Data/Y_train.npy')\n","Y_test = np.load(path+'Data/Y_test.npy')\n","Y_dev = np.load(path+'Data/Y_dev.npy')\n","X_train = np.concatenate((X_train, X_test), axis=0)\n","Y_train = np.concatenate((Y_train, Y_test), axis=0)\n","print(Y_train.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(179247, 10)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZKQtNGuXu3o9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":357},"executionInfo":{"status":"ok","timestamp":1596094791238,"user_tz":-330,"elapsed":9798,"user":{"displayName":"Karan Aggarwal","photoUrl":"","userId":"14241836093579771442"}},"outputId":"c3f7d6e5-e9bc-451f-f8fd-42db8ebe33b3"},"source":["def pretrained_embedding_layer(emb_matrix):\n","    embedding_layer = Embedding(emb_matrix.shape[0],emb_matrix.shape[1], trainable=False)\n","    embedding_layer.build((None,))\n","    embedding_layer.set_weights([emb_matrix])\n","    return embedding_layer\n","\n","def make_model(input_shape, emb_matrix):\n","    phrase_indices = Input(shape=input_shape, dtype = 'int32')\n","    emb_layer = pretrained_embedding_layer(emb_matrix)\n","    embeddings = emb_layer(phrase_indices)   \n","    X = Bidirectional(LSTM(128, return_sequences=True))(embeddings)\n","    X = Bidirectional(LSTM(128))(X)\n","    X = Dense(512, activation='relu')(X)\n","    X = Dense(10, activation='softmax')(X)\n","    model = Model(inputs=phrase_indices, outputs=X)\n","    return model\n","\n","model = make_model((max_len,), emb_matrix)\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.summary()\n","checkpoint_path = \"/content/drive/My Drive/Sentiment Analysis/Data/cpnew11.ckpt\"\n","cp_callback = ModelCheckpoint(filepath=checkpoint_path, verbose=1, save_weights_only=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         (None, 56)                0         \n","_________________________________________________________________\n","embedding_1 (Embedding)      (None, 56, 100)           40000200  \n","_________________________________________________________________\n","bidirectional_1 (Bidirection (None, 56, 256)           234496    \n","_________________________________________________________________\n","bidirectional_2 (Bidirection (None, 256)               394240    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 512)               131584    \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 10)                5130      \n","=================================================================\n","Total params: 40,765,650\n","Trainable params: 765,450\n","Non-trainable params: 40,000,200\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mmann21hvNUB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1596095949235,"user_tz":-330,"elapsed":1167787,"user":{"displayName":"Karan Aggarwal","photoUrl":"","userId":"14241836093579771442"}},"outputId":"70bfc4af-a4af-430a-9bb7-2eda385fecad"},"source":["model.fit(X_train, Y_train, epochs = 20, batch_size = 3000, shuffle=True, callbacks=[cp_callback])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","179247/179247 [==============================] - 65s 360us/step - loss: 1.7694 - accuracy: 0.3515\n","\n","Epoch 00001: saving model to /content/drive/My Drive/Sentiment Analysis/Data/cpnew11.ckpt\n","Epoch 2/20\n","179247/179247 [==============================] - 62s 345us/step - loss: 1.5700 - accuracy: 0.3958\n","\n","Epoch 00002: saving model to /content/drive/My Drive/Sentiment Analysis/Data/cpnew11.ckpt\n","Epoch 3/20\n","179247/179247 [==============================] - 62s 345us/step - loss: 1.5280 - accuracy: 0.4056\n","\n","Epoch 00003: saving model to /content/drive/My Drive/Sentiment Analysis/Data/cpnew11.ckpt\n","Epoch 4/20\n","179247/179247 [==============================] - 62s 344us/step - loss: 1.5057 - accuracy: 0.4124\n","\n","Epoch 00004: saving model to /content/drive/My Drive/Sentiment Analysis/Data/cpnew11.ckpt\n","Epoch 5/20\n","179247/179247 [==============================] - 62s 345us/step - loss: 1.4910 - accuracy: 0.4147\n","\n","Epoch 00005: saving model to /content/drive/My Drive/Sentiment Analysis/Data/cpnew11.ckpt\n","Epoch 6/20\n","179247/179247 [==============================] - 62s 346us/step - loss: 1.4733 - accuracy: 0.4187\n","\n","Epoch 00006: saving model to /content/drive/My Drive/Sentiment Analysis/Data/cpnew11.ckpt\n","Epoch 7/20\n","179247/179247 [==============================] - 62s 346us/step - loss: 1.4727 - accuracy: 0.4193\n","\n","Epoch 00007: saving model to /content/drive/My Drive/Sentiment Analysis/Data/cpnew11.ckpt\n","Epoch 8/20\n","179247/179247 [==============================] - 62s 344us/step - loss: 1.4513 - accuracy: 0.4249\n","\n","Epoch 00008: saving model to /content/drive/My Drive/Sentiment Analysis/Data/cpnew11.ckpt\n","Epoch 9/20\n","179247/179247 [==============================] - 62s 346us/step - loss: 1.4531 - accuracy: 0.4224\n","\n","Epoch 00009: saving model to /content/drive/My Drive/Sentiment Analysis/Data/cpnew11.ckpt\n","Epoch 10/20\n","179247/179247 [==============================] - 62s 344us/step - loss: 1.4277 - accuracy: 0.4302\n","\n","Epoch 00010: saving model to /content/drive/My Drive/Sentiment Analysis/Data/cpnew11.ckpt\n","Epoch 11/20\n","179247/179247 [==============================] - 62s 345us/step - loss: 1.4255 - accuracy: 0.4308\n","\n","Epoch 00011: saving model to /content/drive/My Drive/Sentiment Analysis/Data/cpnew11.ckpt\n","Epoch 12/20\n","179247/179247 [==============================] - 62s 345us/step - loss: 1.4041 - accuracy: 0.4375\n","\n","Epoch 00012: saving model to /content/drive/My Drive/Sentiment Analysis/Data/cpnew11.ckpt\n","Epoch 13/20\n","179247/179247 [==============================] - 62s 344us/step - loss: 1.4343 - accuracy: 0.4290\n","\n","Epoch 00013: saving model to /content/drive/My Drive/Sentiment Analysis/Data/cpnew11.ckpt\n","Epoch 14/20\n","179247/179247 [==============================] - 62s 344us/step - loss: 1.4030 - accuracy: 0.4374\n","\n","Epoch 00014: saving model to /content/drive/My Drive/Sentiment Analysis/Data/cpnew11.ckpt\n","Epoch 15/20\n","179247/179247 [==============================] - 61s 342us/step - loss: 1.3860 - accuracy: 0.4421\n","\n","Epoch 00015: saving model to /content/drive/My Drive/Sentiment Analysis/Data/cpnew11.ckpt\n","Epoch 16/20\n","179247/179247 [==============================] - 61s 343us/step - loss: 1.3728 - accuracy: 0.4430\n","\n","Epoch 00016: saving model to /content/drive/My Drive/Sentiment Analysis/Data/cpnew11.ckpt\n","Epoch 17/20\n","179247/179247 [==============================] - 62s 346us/step - loss: 1.3583 - accuracy: 0.4497\n","\n","Epoch 00017: saving model to /content/drive/My Drive/Sentiment Analysis/Data/cpnew11.ckpt\n","Epoch 18/20\n","179247/179247 [==============================] - 62s 343us/step - loss: 1.3468 - accuracy: 0.4540\n","\n","Epoch 00018: saving model to /content/drive/My Drive/Sentiment Analysis/Data/cpnew11.ckpt\n","Epoch 19/20\n"," 15000/179247 [=>............................] - ETA: 56s - loss: 1.3547 - accuracy: 0.4475"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-1cf1e7028b35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcp_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/Sentiment Analysis/Data/model11.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"xatd_MI3v7KZ","colab_type":"code","colab":{}},"source":["model.save_weights(\"/content/drive/My Drive/Sentiment Analysis/Data/model11.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_fMAwlci2aAc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1596084908171,"user_tz":-330,"elapsed":68523,"user":{"displayName":"Karan Aggarwal","photoUrl":"","userId":"14241836093579771442"}},"outputId":"f2d3429b-9527-47b8-9cc5-b838e841df36"},"source":["weight_path = '/content/drive/My Drive/Sentiment Analysis/Data/model11.h5'\n","loaded_model = make_model((max_len,), emb_matrix)\n","loaded_model.load_weights(weight_path)\n","loaded_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","loss_dev, acc_dev = loaded_model.evaluate(X_dev, Y_dev)\n","print(loss_dev, acc_dev)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["59985/59985 [==============================] - 64s 1ms/step\n","1.5040373155988633 0.4160206615924835\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x4g7Z9ipEbr_","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}