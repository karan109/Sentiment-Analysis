{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"fileinput.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNiaMPeDbWryWcFM+CR+UUK"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"UEYq04WazaHf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595247468978,"user_tz":-330,"elapsed":1817,"user":{"displayName":"Karan Aggarwal","photoUrl":"","userId":"14241836093579771442"}},"outputId":"ef51570c-6d9d-4c38-dcf3-1da0f57ae134"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"e8ARsHXezeGv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1595248443686,"user_tz":-330,"elapsed":2046,"user":{"displayName":"Karan Aggarwal","photoUrl":"","userId":"14241836093579771442"}},"outputId":"a13f5b4f-16ac-47d5-a94c-72434de3c09d"},"source":["import pandas as pd\n","import numpy as np\n","import codecs\n","import math\n","import nltk\n","from nltk.tokenize import RegexpTokenizer\n","from keras.layers.embeddings import Embedding\n","from keras.layers import Dense, Input\n","from keras.layers import LSTM\n","from keras.layers import Bidirectional\n","from keras.models import Model\n","from keras.models import load_model\n","nltk.download('punkt')\n","from nltk import sent_tokenize"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"F-QpVE8QEeDU","colab_type":"code","colab":{}},"source":["path = '/content/drive/My Drive/Sentiment Analysis/'\n","\n","# Load embeddings\n","def load_embeddings(embedding_path, glove_len):\n","  weight_vectors = [np.zeros((glove_len, ))]\n","  word_idx = {}\n","  with codecs.open(embedding_path, encoding='utf-8') as f:\n","    for line in f:\n","      word, vec = line.split(u' ', 1)\n","      word_idx[word.lower()] = len(weight_vectors)\n","      weight_vectors.append(np.array(vec.split(), dtype=np.float32))\n","  word_idx[u'-LRB-'] = word_idx.pop(u'(')\n","  word_idx[u'-RRB-'] = word_idx.pop(u')')\n","  weight_vectors.append(np.random.uniform(\n","      -0.05, 0.05, weight_vectors[0].shape).astype(np.float32))\n","  return np.asarray(np.stack(weight_vectors)), word_idx\n","\n","emb_matrix, word_idx = load_embeddings(path+'Data/glove_6B_100d.txt', 100)\n","max_len = 56"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5V-gumdA0M01","colab_type":"code","colab":{}},"source":["# convert list of words to their corresponding indices to feed to the network\n","def get_example_X(sentence_words, word_idx, max_seq_len):\n","    maxSeqLength = max_seq_len\n","    ids = np.zeros((1, maxSeqLength), dtype='int32')\n","    word_idx_lwr =  {k.lower(): v for k, v in word_idx.items()}\n","    i = 0\n","    for word in sentence_words:\n","        word_lwr = word.lower()\n","        try:\n","            ids[0][i] =  word_idx_lwr[word_lwr]\n","\n","        except Exception as e:\n","            ids[0][i] = len(word_idx_lwr)+1\n","        i = i + 1\n","    return ids\n","\n","def pretrained_embedding_layer(emb_matrix):\n","    embedding_layer = Embedding(emb_matrix.shape[0],emb_matrix.shape[1], trainable=False)\n","    embedding_layer.build((None,))\n","    embedding_layer.set_weights([emb_matrix])\n","    return embedding_layer\n","\n","# Pre processing of a sentence\n","def process(sentence):\n","  tokenizer = RegexpTokenizer(r'\\w+')\n","  sentence_words = tokenizer.tokenize(sentence)\n","  sentences = [sentence_words[i*int(max_len/2):min(i*int(max_len/2)+max_len, max_len)] for i in range(0, math.ceil(len(sentence_words)/max_len))]\n","  return sentences\n","\n","# Model Architecture\n","def make_model(input_shape, emb_matrix):\n","    phrase_indices = Input(shape=input_shape, dtype = 'int32')\n","    emb_layer = pretrained_embedding_layer(emb_matrix)\n","    embeddings = emb_layer(phrase_indices)   \n","    X = Bidirectional(LSTM(128, return_sequences=True))(embeddings)\n","    X = Bidirectional(LSTM(128))(X)\n","    X = Dense(512, activation='relu')(X)\n","    X = Dense(10, activation='softmax')(X)\n","    model = Model(inputs=phrase_indices, outputs=X)\n","    return model\n","\n","weight_path = path+'Data/model6.h5'\n","model = make_model((max_len,), emb_matrix)\n","model.load_weights(weight_path)\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# Get sentiment scores\n","def evaluate(sentences, model):\n","    if sentences != []:\n","      total_score = 0\n","      total_len = 0\n","      for part in sentences:\n","        X_example = get_example_X(part, word_idx, max_len)\n","        score = model.predict(X_example, batch_size=1, verbose=0)\n","        top_3_index = np.argsort(score)[0][-3:]\n","        top_3_scores = score[0][top_3_index]\n","        top_3_weights = top_3_scores/np.sum(top_3_scores)\n","        single_score_dot = np.round(np.dot(top_3_index, top_3_weights)/10, decimals = 2)\n","        total_score += single_score_dot*len(part)\n","        total_len += len(part)\n","      return round(total_score/total_len, 2)\n","    else:\n","      return -1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_UunVJ7yBdaB","colab_type":"code","colab":{}},"source":["# Function which takes the input and output file paths as argument and ouputs the sentiment score of each sentence\n","def output(input_file, output_file):\n","  f_input = open(input_file, 'r')\n","  f_output = open(output_file, 'w')\n","  lines = f_input.readlines()\n","  for line in lines:\n","    # SPlit line into relevant sentences\n","    sentences = sent_tokenize(line)\n","    for sentence in sentences:\n","      # Get score of each sentence\n","      score = evaluate(process(sentence), model)\n","      # If empty sentence, do not return anything\n","      if score != -1:\n","        # Write output to output file\n","        f_output.write(line+'\\n'+str(score)+'\\n')\n","  f_input.close()\n","  f_output.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uVqfoZrb-b-N","colab_type":"code","colab":{}},"source":["# Example\n","output(path+'Data/testfile.txt', path+'Data/Output/output.txt')"],"execution_count":null,"outputs":[]}]}